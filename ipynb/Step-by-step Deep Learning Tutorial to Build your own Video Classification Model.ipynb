{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from website: https://www.analyticsvidhya.com/blog/2019/09/step-by-step-deep-learning-tutorial-video-classification-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ok\n"
     ]
    }
   ],
   "source": [
    "import cv2     # for capturing videos\n",
    "import math   # for mathematical operations\n",
    "import matplotlib.pyplot as plt    # for plotting the images\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image   # for preprocessing the images\n",
    "import numpy as np    # for mathematical operations\n",
    "from keras.utils import np_utils\n",
    "from skimage.transform import resize   # for resizing images\n",
    "from sklearn.model_selection import train_test_split\n",
    "from glob import glob\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "print('ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Exploring the Video Classification Dataset, we only do the classification in first 10 classess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mainpath = '/Users/zhennongchen/Documents/Zhennong_Video Classification/Data/UCF101'\n",
    "txtpath = os.path.join(mainpath,'UCF_TrainTestlist')\n",
    "videopath = os.path.join(mainpath,'UCF_Video_sub_classes1')\n",
    "\n",
    "f = open(os.path.join(txtpath,\"trainlist01.txt\"),'r')\n",
    "temp = f.read()\n",
    "video_list = temp.split('\\n')\n",
    "sub_video_list = []\n",
    "for v in video_list[:-1]:\n",
    "    file = v.split(' ')[0]\n",
    "    if os.path.isfile(os.path.join(videopath,file)) == True:\n",
    "        sub_video_list.append(file)\n",
    "train = pd.DataFrame()\n",
    "train['video_name'] = sub_video_list\n",
    "f.close()\n",
    "\n",
    "    \n",
    "f = open(os.path.join(txtpath,\"testlist01.txt\"),'r')\n",
    "temp = f.read()\n",
    "video_list = temp.split('\\n')\n",
    "sub_video_list = []\n",
    "for v in video_list[:-1]:\n",
    "    file = v.split(' ')[0]\n",
    "    if os.path.isfile(os.path.join(videopath,file)) == True:\n",
    "        sub_video_list.append(file)\n",
    "test = pd.DataFrame()\n",
    "test['video_name'] = sub_video_list\n",
    "f.close()   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>tag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Basketball/v_Basketball_g01_c01.avi</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Basketball/v_Basketball_g01_c02.avi</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Basketball/v_Basketball_g01_c03.avi</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basketball/v_Basketball_g01_c04.avi</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Basketball/v_Basketball_g01_c05.avi</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            video_name         tag\n",
       "0  Basketball/v_Basketball_g01_c01.avi  Basketball\n",
       "1  Basketball/v_Basketball_g01_c02.avi  Basketball\n",
       "2  Basketball/v_Basketball_g01_c03.avi  Basketball\n",
       "3  Basketball/v_Basketball_g01_c04.avi  Basketball\n",
       "4  Basketball/v_Basketball_g01_c05.avi  Basketball"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create tags for training videos and test videos\n",
    "train_video_tag = []\n",
    "for i in range(train.shape[0]):\n",
    "    train_video_tag.append(train['video_name'][i].split('/')[0])\n",
    "train['tag'] = train_video_tag\n",
    "\n",
    "test_video_tag = []\n",
    "for i in range(test.shape[0]):\n",
    "    test_video_tag.append(test['video_name'][i].split('/')[0])\n",
    "test['tag'] = test_video_tag\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 193/193 [00:07<00:00, 26.31it/s]\n",
      "  4%|▍         | 3/72 [00:00<00:03, 19.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done training set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 72/72 [00:02<00:00, 30.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# extract time frames from training and test videos\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    videoFile = train['video_name'][i]\n",
    "    cap = cv2.VideoCapture(os.path.join(videopath,videoFile.split(' ')[0].split('/')[0],videoFile.split(' ')[0].split('/')[1]))\n",
    "    frameRate = cap.get(5)\n",
    "    \n",
    "    x = 1\n",
    "    count = 0\n",
    "    while(cap.isOpened()):\n",
    "        frameId = cap.get(1)\n",
    "        ret,frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        if (frameId % math.floor(frameRate) == 0):\n",
    "            filename = os.path.join(mainpath,'train_1/'+videoFile.split('/')[1].split(' ')[0]+\"_frame%d.jpg\"%count)\n",
    "            cv2.imwrite(filename,frame)\n",
    "            count += 1\n",
    "    cap.release()\n",
    "print('done training set')\n",
    "\n",
    "for i in tqdm(range(test.shape[0])):\n",
    "    videoFile = test['video_name'][i]\n",
    "    cap = cv2.VideoCapture(os.path.join(videopath,videoFile.split(' ')[0].split('/')[0],videoFile.split(' ')[0].split('/')[1]))\n",
    "    frameRate = cap.get(5)\n",
    "    \n",
    "    x = 1\n",
    "    count = 0\n",
    "    while(cap.isOpened()):\n",
    "        frameId = cap.get(1)\n",
    "        ret,frame = cap.read()\n",
    "        if (ret != True):\n",
    "            break\n",
    "        if (frameId % math.floor(frameRate) == 0):\n",
    "            filename = os.path.join(mainpath,'test_1/'+videoFile.split('/')[1].split(' ')[0]+\"_frame%d.jpg\"%count)\n",
    "            cv2.imwrite(filename,frame)\n",
    "            count += 1\n",
    "    cap.release()\n",
    "print('done test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 907/907 [00:00<00:00, 434174.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# save the name of these frames with tag in a .csv file.\n",
    "images = glob(os.path.join(mainpath,'train_1','*.jpg'))\n",
    "train_image = []\n",
    "train_class = []\n",
    "for i in tqdm(range(len(images))):\n",
    "    train_image.append(images[i].split('/')[-1])\n",
    "    train_class.append(images[i].split('/')[-1].split('_')[1])\n",
    "\n",
    "# store in a dataframe\n",
    "train_data = pd.DataFrame()\n",
    "train_data['image'] = train_image\n",
    "train_data['class'] = train_class\n",
    "\n",
    "# convert the dataframe into csv file\n",
    "train_data.to_csv(os.path.join(mainpath,'train_new.csv'),header=True, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: training the video classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense, InputLayer, Dropout, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalMaxPooling2D\n",
    "from keras.preprocessing import image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(907, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v_Basketball_g23_c05.avi_frame2.jpg</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v_Basketball_g10_c03.avi_frame3.jpg</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v_Basketball_g15_c07.avi_frame0.jpg</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>v_Basketball_g20_c04.avi_frame2.jpg</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>v_Basketball_g16_c06.avi_frame0.jpg</td>\n",
       "      <td>Basketball</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 image       class\n",
       "0  v_Basketball_g23_c05.avi_frame2.jpg  Basketball\n",
       "1  v_Basketball_g10_c03.avi_frame3.jpg  Basketball\n",
       "2  v_Basketball_g15_c07.avi_frame0.jpg  Basketball\n",
       "3  v_Basketball_g20_c04.avi_frame2.jpg  Basketball\n",
       "4  v_Basketball_g16_c06.avi_frame0.jpg  Basketball"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(os.path.join(mainpath,'train_new.csv'))\n",
    "# in order to make smaller size of data, we only pick the first 30000\n",
    "print(train.shape)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 907/907 [00:02<00:00, 373.37it/s]\n"
     ]
    }
   ],
   "source": [
    "train_image = []\n",
    "for i in tqdm(range(train.shape[0])):\n",
    "    img = image.load_img(os.path.join(mainpath,'train_1',train['image'][i]),target_size=(224,224,3))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255 # normalize the pixel value\n",
    "    train_image.append(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.asarray(train_image)\n",
    "# preprocessing the input for VGG\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "X = preprocess_input(X,mode = 'tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(725, 224, 224, 3) (182, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "# create training and validation set\n",
    "y = train['class']\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,random_state=42,test_size=0.2,stratify = y)\n",
    "# here , striatify = y keeps the similar distribution of classess in both the training as well as the validation set.\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = pd.get_dummies(y_train)\n",
    "y_test = pd.get_dummies(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /anaconda3/envs/tensorflow_cpu/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "(725, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "# define the architescture of the video classification model\n",
    "base_model = VGG16(weights='imagenet',include_top=False,input_shape=(224,224,3))\n",
    "X_train = base_model.predict(X_train)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(182, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "X_test = base_model.predict(X_test)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(725, 25088) (182, 25088)\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.reshape(X_train.shape[0],7*7*512)\n",
    "X_test = X_test.reshape(X_test.shape[0],7*7*512)\n",
    "max_val = X_train.max()\n",
    "X_train = X_train/max_val\n",
    "X_test = X_test/max_val\n",
    "print(X_train.shape,X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build FC model\n",
    "model = Sequential()\n",
    "model.add(InputLayer((7*7*512,)))    # input layer\n",
    "model.add(Dense(units=1024, activation='relu'))   # hidden layer\n",
    "model.add(Dropout(0.5))      # adding dropout, so there is sync on training and validation\n",
    "model.add(Dense(units=512, activation='relu'))    # hidden layer, increase number of layers to increase accuracy on training\n",
    "model.add(Dropout(0.5))      # adding dropout\n",
    "model.add(Dense(units=256, activation='relu'))    # hidden layer\n",
    "model.add(Dropout(0.5))      # adding dropout\n",
    "model.add(Dense(units=128, activation='relu'))    # hidden layer\n",
    "model.add(Dropout(0.5))      # adding dropout\n",
    "model.add(Dense(units=64, activation='relu'))    # hidden layer\n",
    "model.add(Dropout(0.5))      # adding dropout\n",
    "model.add(Dense(2, activation='softmax'))            # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
    "class_weights = compute_class_weight('balanced',np.unique(train['class']), train['class'])  # computing weights of different classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 725 samples, validate on 182 samples\n",
      "Epoch 1/100\n",
      "725/725 [==============================] - 8s 11ms/step - loss: 0.7336 - acc: 0.5159 - val_loss: 0.6836 - val_acc: 0.6099\n",
      "Epoch 2/100\n",
      "725/725 [==============================] - 3s 5ms/step - loss: 0.6985 - acc: 0.5517 - val_loss: 0.6865 - val_acc: 0.6099\n",
      "Epoch 3/100\n",
      "725/725 [==============================] - 3s 5ms/step - loss: 0.6885 - acc: 0.5710 - val_loss: 0.6831 - val_acc: 0.6099\n",
      "Epoch 4/100\n",
      "725/725 [==============================] - 3s 5ms/step - loss: 0.7014 - acc: 0.5545 - val_loss: 0.6840 - val_acc: 0.6099\n",
      "Epoch 5/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6784 - acc: 0.5931 - val_loss: 0.6833 - val_acc: 0.6099\n",
      "Epoch 6/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6713 - acc: 0.6097 - val_loss: 0.6796 - val_acc: 0.6099\n",
      "Epoch 7/100\n",
      "725/725 [==============================] - 3s 5ms/step - loss: 0.6793 - acc: 0.6041 - val_loss: 0.6776 - val_acc: 0.6099\n",
      "Epoch 8/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6870 - acc: 0.5876 - val_loss: 0.6767 - val_acc: 0.6099\n",
      "Epoch 9/100\n",
      "725/725 [==============================] - 3s 5ms/step - loss: 0.6766 - acc: 0.5959 - val_loss: 0.6774 - val_acc: 0.6099\n",
      "Epoch 10/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6778 - acc: 0.6014 - val_loss: 0.6773 - val_acc: 0.6099\n",
      "Epoch 11/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6792 - acc: 0.5986 - val_loss: 0.6772 - val_acc: 0.6099\n",
      "Epoch 12/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6771 - acc: 0.6152 - val_loss: 0.6784 - val_acc: 0.6099\n",
      "Epoch 13/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6809 - acc: 0.6097 - val_loss: 0.6789 - val_acc: 0.6099\n",
      "Epoch 14/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6671 - acc: 0.6138 - val_loss: 0.6780 - val_acc: 0.6099\n",
      "Epoch 15/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6739 - acc: 0.6097 - val_loss: 0.6772 - val_acc: 0.6099\n",
      "Epoch 16/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6686 - acc: 0.6138 - val_loss: 0.6761 - val_acc: 0.6099\n",
      "Epoch 17/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6743 - acc: 0.6069 - val_loss: 0.6739 - val_acc: 0.6099\n",
      "Epoch 18/100\n",
      "725/725 [==============================] - 3s 5ms/step - loss: 0.6711 - acc: 0.6041 - val_loss: 0.6745 - val_acc: 0.6099\n",
      "Epoch 19/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6729 - acc: 0.6083 - val_loss: 0.6747 - val_acc: 0.6099\n",
      "Epoch 20/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6680 - acc: 0.6124 - val_loss: 0.6743 - val_acc: 0.6099\n",
      "Epoch 21/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6726 - acc: 0.6152 - val_loss: 0.6746 - val_acc: 0.6099\n",
      "Epoch 22/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6724 - acc: 0.6152 - val_loss: 0.6756 - val_acc: 0.6099\n",
      "Epoch 23/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6713 - acc: 0.6166 - val_loss: 0.6757 - val_acc: 0.6099\n",
      "Epoch 24/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6721 - acc: 0.6097 - val_loss: 0.6749 - val_acc: 0.6099\n",
      "Epoch 25/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6683 - acc: 0.6138 - val_loss: 0.6743 - val_acc: 0.6099\n",
      "Epoch 26/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6739 - acc: 0.6124 - val_loss: 0.6749 - val_acc: 0.6099\n",
      "Epoch 27/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6700 - acc: 0.6124 - val_loss: 0.6748 - val_acc: 0.6099\n",
      "Epoch 28/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6668 - acc: 0.6152 - val_loss: 0.6743 - val_acc: 0.6099\n",
      "Epoch 29/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6727 - acc: 0.6124 - val_loss: 0.6743 - val_acc: 0.6099\n",
      "Epoch 30/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6777 - acc: 0.6110 - val_loss: 0.6747 - val_acc: 0.6099\n",
      "Epoch 31/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6687 - acc: 0.6138 - val_loss: 0.6741 - val_acc: 0.6099\n",
      "Epoch 32/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6659 - acc: 0.6097 - val_loss: 0.6728 - val_acc: 0.6099\n",
      "Epoch 33/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6703 - acc: 0.6110 - val_loss: 0.6715 - val_acc: 0.6099\n",
      "Epoch 34/100\n",
      "725/725 [==============================] - 3s 5ms/step - loss: 0.6764 - acc: 0.6110 - val_loss: 0.6721 - val_acc: 0.6099\n",
      "Epoch 35/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6745 - acc: 0.6138 - val_loss: 0.6732 - val_acc: 0.6099\n",
      "Epoch 36/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6728 - acc: 0.6124 - val_loss: 0.6732 - val_acc: 0.6099\n",
      "Epoch 37/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6703 - acc: 0.6138 - val_loss: 0.6717 - val_acc: 0.6099\n",
      "Epoch 38/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6677 - acc: 0.6124 - val_loss: 0.6705 - val_acc: 0.6099\n",
      "Epoch 39/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6746 - acc: 0.6124 - val_loss: 0.6707 - val_acc: 0.6099\n",
      "Epoch 40/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6703 - acc: 0.6110 - val_loss: 0.6706 - val_acc: 0.6099\n",
      "Epoch 41/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6713 - acc: 0.6124 - val_loss: 0.6709 - val_acc: 0.6099\n",
      "Epoch 42/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6693 - acc: 0.6124 - val_loss: 0.6705 - val_acc: 0.6099\n",
      "Epoch 43/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6690 - acc: 0.6124 - val_loss: 0.6698 - val_acc: 0.6099\n",
      "Epoch 44/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6683 - acc: 0.6124 - val_loss: 0.6693 - val_acc: 0.6099\n",
      "Epoch 45/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6678 - acc: 0.6124 - val_loss: 0.6687 - val_acc: 0.6099\n",
      "Epoch 46/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6686 - acc: 0.6124 - val_loss: 0.6685 - val_acc: 0.6099\n",
      "Epoch 47/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6685 - acc: 0.6124 - val_loss: 0.6687 - val_acc: 0.6099\n",
      "Epoch 48/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6683 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 49/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6677 - acc: 0.6124 - val_loss: 0.6687 - val_acc: 0.6099\n",
      "Epoch 50/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6646 - acc: 0.6124 - val_loss: 0.6684 - val_acc: 0.6099\n",
      "Epoch 51/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6699 - acc: 0.6124 - val_loss: 0.6684 - val_acc: 0.6099\n",
      "Epoch 52/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6685 - acc: 0.6124 - val_loss: 0.6689 - val_acc: 0.6099\n",
      "Epoch 53/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6666 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 54/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6670 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 55/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6682 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 56/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6680 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 57/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6679 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 58/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6671 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 59/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6686 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 60/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6694 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 61/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6702 - acc: 0.6124 - val_loss: 0.6689 - val_acc: 0.6099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6662 - acc: 0.6124 - val_loss: 0.6689 - val_acc: 0.6099\n",
      "Epoch 63/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6687 - acc: 0.6124 - val_loss: 0.6689 - val_acc: 0.6099\n",
      "Epoch 64/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6663 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 65/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6690 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 66/100\n",
      "725/725 [==============================] - 4s 6ms/step - loss: 0.6679 - acc: 0.6124 - val_loss: 0.6689 - val_acc: 0.6099\n",
      "Epoch 67/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6680 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 68/100\n",
      "725/725 [==============================] - 5s 7ms/step - loss: 0.6695 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 69/100\n",
      "725/725 [==============================] - 5s 6ms/step - loss: 0.6667 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 70/100\n",
      "725/725 [==============================] - 5s 7ms/step - loss: 0.6678 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 71/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6662 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 72/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6714 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 73/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6662 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 74/100\n",
      "725/725 [==============================] - 5s 7ms/step - loss: 0.6689 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 75/100\n",
      "725/725 [==============================] - 5s 7ms/step - loss: 0.6676 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 76/100\n",
      "725/725 [==============================] - 4s 6ms/step - loss: 0.6669 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 77/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6657 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 78/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6674 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 79/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6679 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 80/100\n",
      "725/725 [==============================] - 4s 6ms/step - loss: 0.6673 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 81/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6696 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 82/100\n",
      "725/725 [==============================] - 5s 6ms/step - loss: 0.6674 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 83/100\n",
      "725/725 [==============================] - 4s 6ms/step - loss: 0.6687 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 84/100\n",
      "725/725 [==============================] - 4s 6ms/step - loss: 0.6677 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 85/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6678 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 86/100\n",
      "725/725 [==============================] - 4s 6ms/step - loss: 0.6699 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 87/100\n",
      "725/725 [==============================] - 6s 8ms/step - loss: 0.6663 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 88/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6668 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 89/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6688 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 90/100\n",
      "725/725 [==============================] - 5s 6ms/step - loss: 0.6689 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 91/100\n",
      "725/725 [==============================] - 4s 6ms/step - loss: 0.6665 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 92/100\n",
      "725/725 [==============================] - 4s 6ms/step - loss: 0.6678 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 93/100\n",
      "725/725 [==============================] - 4s 6ms/step - loss: 0.6663 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 94/100\n",
      "725/725 [==============================] - 4s 6ms/step - loss: 0.6694 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 95/100\n",
      "725/725 [==============================] - 5s 6ms/step - loss: 0.6674 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 96/100\n",
      "725/725 [==============================] - 4s 5ms/step - loss: 0.6689 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 97/100\n",
      "725/725 [==============================] - 4s 6ms/step - loss: 0.6674 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 98/100\n",
      "725/725 [==============================] - 5s 7ms/step - loss: 0.6670 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 99/100\n",
      "725/725 [==============================] - 5s 7ms/step - loss: 0.6687 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n",
      "Epoch 100/100\n",
      "725/725 [==============================] - 4s 6ms/step - loss: 0.6656 - acc: 0.6124 - val_loss: 0.6688 - val_acc: 0.6099\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1a8aa83278>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "mcp_save = ModelCheckpoint(os.path.join(mainpath,'best_weight.hdf5'), save_best_only=True, verbose=1, monitor='val_loss', mode='min')\n",
    "\n",
    "# compile the model\n",
    "model.compile(loss = 'categorical_crossentropy',optimizer = 'Adam',metrics=['accuracy'])\n",
    "\n",
    "# training the model\n",
    "model.fit(X_train,y_train,epochs=100,validation_data=(X_test,y_test),class_weight=class_weights,callbacks=[mcp_save],batch_size=145)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate our video classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(weights='imagenet',include_top=False)\n",
    "# build FC model\n",
    "m = Sequential()\n",
    "m.add(InputLayer((7*7*512,)))    # input layer\n",
    "m.add(Dense(units=1024, activation='relu'))   # hidden layer\n",
    "m.add(Dropout(0.5))      # adding dropout, so there is sync on training and validation\n",
    "m.add(Dense(units=512, activation='relu'))    # hidden layer, increase number of layers to increase accuracy on training\n",
    "m.add(Dropout(0.5))      # adding dropout\n",
    "m.add(Dense(units=256, activation='relu'))    # hidden layer\n",
    "m.add(Dropout(0.5))      # adding dropout\n",
    "m.add(Dense(units=128, activation='relu'))    # hidden layer\n",
    "m.add(Dropout(0.5))      # adding dropout\n",
    "m.add(Dense(units=64, activation='relu'))    # hidden layer\n",
    "m.add(Dropout(0.5))      # adding dropout\n",
    "m.add(Dense(2, activation='softmax'))            # output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.load_weights(os.path.join(mainpath,'best_weight.hdf5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compiling the model\n",
    "m.compile(loss='categorical_crossentropy',optimizer='Adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [00:00<00:00, 234005.51it/s]\n"
     ]
    }
   ],
   "source": [
    "images = glob(os.path.join(mainpath,'test_1','*.jpg'))\n",
    "test_image = []\n",
    "test_class = []\n",
    "for i in tqdm(range(len(images))):\n",
    "    test_image.append(images[i].split('/')[-1])\n",
    "    test_class.append(images[i].split('/')[-1].split('_')[1])\n",
    "\n",
    "# store in a dataframe\n",
    "test_data = pd.DataFrame()\n",
    "test_data['image'] = test_image\n",
    "test_data['class'] = test_class\n",
    "\n",
    "# convert the dataframe into csv file\n",
    "test_data.to_csv(os.path.join(mainpath,'test_new.csv'),header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 57/263 [00:00<00:00, 561.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(263, 2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 263/263 [00:00<00:00, 548.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(263, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "test = pd.read_csv(os.path.join(mainpath,'test_new.csv'))\n",
    "print(test.shape)\n",
    "test_image = []\n",
    "for i in tqdm(range(test.shape[0])):\n",
    "    img = image.load_img(os.path.join(mainpath,'test_1',test['image'][i]),target_size=(224,224,3))\n",
    "    img = image.img_to_array(img)\n",
    "    img = img/255 # normalize the pixel value\n",
    "    test_image.append(img)\n",
    "predict_X = np.asarray(test_image)\n",
    "print(predict_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import preprocess_input\n",
    "predict_X = preprocess_input(predict_X,mode = 'tf')\n",
    "predict_y = pd.get_dummies(test['class'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(263, 7, 7, 512)\n"
     ]
    }
   ],
   "source": [
    "predict_X = base_model.predict(predict_X)\n",
    "print(predict_X.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_X = predict_X.reshape(predict_X.shape[0],7*7*512)\n",
    "max_val = predict_X.max()\n",
    "predict_X = predict_X / max_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "263/263 [==============================] - 1s 4ms/step\n",
      "acc: 57.03%\n"
     ]
    }
   ],
   "source": [
    "scores = m.evaluate(predict_X,predict_y)\n",
    "print('acc: %.2f%%' %(scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
